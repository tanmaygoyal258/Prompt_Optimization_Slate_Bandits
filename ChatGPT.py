import openai
from basic_LLM import BasicLLM

from azure.identity import (
    AzureCliCredential,
    AuthenticationRecord,
    InteractiveBrowserCredential,
    TokenCachePersistenceOptions
)

from pathlib import Path, PurePath
import tempfile
from time import sleep

class ChatGPT(BasicLLM):
    """_summary_

    Args:
        BasicLLM (_type_): _description_
    """
    def __init__(self, model: str = "gpt-3.5-turbo", sleep_interval: int = 5) -> None:
        """_summary_

        Args:
            model (str, optional): the selected ChatGPT model. Defaults to "gpt-3.5-turbo".
            sleep_interval (int, optional): a time interval to sleep to avoid excessing ChatGPT's limitation of calling frequency. Defaults to 10.
        """
        super().__init__()
        self.client = self.getOpenAIClient()
        self.model = model
        self.sleep_interval = sleep_interval

    def getOpenAIClient(self) -> openai.OpenAI:
        API_KEY = self.get_auth_token("api://trapi/.default")
        deploymentName = 'gpt-35-turbo_1106'
        endpoint = 'gcr/shared'
        API_VERSION = '2024-02-01'
        BASE_URL = 'https://trapi.research.microsoft.com/' + endpoint 
        DEPLOYMENT_ID = deploymentName

        if API_KEY is None:
            raise Exception("API KEY NOT AVAILABLE")

        llm = openai.AzureOpenAI(
                api_key = API_KEY,  
                api_version = API_VERSION,
                azure_endpoint = BASE_URL,
                azure_deployment=DEPLOYMENT_ID
            )
        
        return llm

    def get_auth_token(self,scope: str) -> str:
        # deserialized_auth_record = None

        # auth_token_cache_file_path = str(
        #     PurePath(tempfile.gettempdir(), "auth_token_cache.json")
        # )
        # if self.exists(auth_token_cache_file_path):
        #     auth_record_json = self.read_file(auth_token_cache_file_path)
        #     deserialized_auth_record = AuthenticationRecord.deserialize(auth_record_json)

        # token_cache_persistence_options = TokenCachePersistenceOptions(
        #     allow_unencrypted_storage=True
        # )

        # credential = InteractiveBrowserCredential(
        #     cache_persistence_options=token_cache_persistence_options,
        #     authentication_record=deserialized_auth_record,
        # )

        # auth_token = credential.get_token(scope).token
        # auth_record = credential.authenticate(scopes=[scope])
        # auth_record_json = AuthenticationRecord.serialize(auth_record)

        # self.write_file(auth_token_cache_file_path, auth_record_json)

        # return auth_token

        credential = AzureCliCredential()	# Get the auth token for the required scope.
        auth_token = credential.get_token(scope).token	# Calling authenticate to get the auth record.
        return auth_token

    
    def read_file(self,file_path: str) -> str:
        encodings = ["utf-8-sig", "utf-16"]
        try:
            for encoding in encodings:
                try:
                    with open(file_path, "r", encoding=encoding) as file_handle:
                        return file_handle.read()
                except UnicodeError:
                    continue
        except Exception as exc:
            error_msg = f"Error while reading file '{file_path}': {exc}"
            print(error_msg)
            raise
        return ""


    def write_file(self,file_path: str, file_data, file_encoding: str = "utf-8-sig"):
        try:
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            with open(file_path, "w", encoding=file_encoding) as file_handle:
                file_handle.write(file_data)
        except Exception as exc:
            error_msg = f"Error while writing to file '{file_path}': {exc}"
            print(error_msg)
            raise


    def exists(self,path: str) -> bool:
        try:
            return Path(path).exists()
        except Exception:
            return False

    def get_response(self, prompt: str, n: int = 1, temperature = 0.7) -> str:
        """Get response from ChatGPT

        Args:
            prompt (str): the prompt to be input to ChatGPT

        Returns:
            str: the response generated by ChatGPT
        """
        messages = [{"role": "system", "content": "You are an intelligent assistant."}]
        messages.append({"role": "user", "content": prompt})
        chat = None
        while chat is None:
            try:                
                chat = self.client.chat.completions.create(model=self.model, messages=messages, n=n, temperature=temperature)
            except TimeoutError:
                return ["TimeoutError"]
            except Exception as e:
                print("ChatGPT error: " + str(e))
        return [chat.choices[0].message.content.split("\n")[0] for i in range(len(chat.choices))]

    def reset(self):
        pass